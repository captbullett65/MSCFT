// [DO NOT INCLUDE THIS SECTION IN FORECAST OUTPUT]

[NOTICE: AI WEB ACCESS LIMITATION]
GPT-4 Omni and related AI models do not have full access to real-time internet data. Many websites 
(especially government, medical, and financial) are protected by services like Cloudflare,
which block AI web crawlers unless explicitly allowed.
For accurate forecasting, all recent or time-sensitive data must be manually provided by the user.
Do not assume the model can search or retrieve live information unless confirmed.

This MSCFT template is aligned with GPT-4o capabilities and assumes Research mode is used when current data is needed.

After specifying your forecast question, resolution criteria, and bucket structure,
include the following line before generation begins:

Use the information retrieved to frame your reasoning and support structured forecasting 
as defined in the previously memorized MSCFT Template 4.0B — SWARM Nodes and BIN Integrated.
No improvisation. No format deviation.

This version formally integrates:
// Structured Swarm Section — Applies only if forecast used multi-node reasoning
// Mode: Structured Swarm (7 Nodes, MSCFT.MS-CMT applied internally)
// Node A: Research Node — framing, question structure, source listing
// Node B: Analytical Node — probability estimate, reasoning, BIN Model
// Node C: Synthesis Node — internal application of MSCFT.MS-CMT logic for final output
// Node D: Interpretation Node — applies advanced model-theoretic analysis of LLM behavior or forecast uncertainty.
// Node D supports three analytical modes:
// • (1) Markov Chain Model — interprets LLM behavior as finite-state transitions based on token prediction probabilities.
// • (2) Entropy Model — uses Shannon entropy (H(p) = -∑ p log p) to quantify uncertainty, confidence, and forecast noise.
// • (3) KL Divergence Model — applies relative entropy (D_KL(P‖Q) = ∑ P(x) log(P(x)/Q(x))) to compare forecast distributions, assess belief shifts, or quantify information gain.
// Node E: Time Series Modeling Node — applies mathematical inference to temporal datasets, including AR, MA, ARIMA, ETS, Fourier series, and spectral entropy models.
// Node F: Retrieval-Augmented Generation (RAG) Node — manages the use of retrieved external sources, maps scope alignment, evaluates forecast contamination, and enforces human-in-the-loop validation.
// Node G: Meta-Curation and Data Integrity Node — filters low-quality or adversarial data using meta-learning algorithms (e.g., DataRater), applying inner/outer loop optimization for upstream data quality assurance.
// Only Node C produces formal output using MSCFT format.
// Node Invocation Declaration: Nodes Used:
- A, B, B.1, B.2, B.3, C, D, D.1, D.2, D.3, E, E.1, E.2, E.3, E.4, E.5, E.6, E.7
- F, F.1, F.2, F.3, F.4, F.5, F.6
- G, G.1, G.2, G.3, G.4, G.5, G.6

// MSCFT plain mode locked. No formatting. No ASCII. No inline interpretation. And no deviation. No summarization of the template.

\[END OF NON-OUTPUT SECTION]

MSCFT Template Version 4.2 SWARM nodes and BIN Integrated — 
Node D for Interpretation; Node E for Time Series Modeling;
Node F for Retrieval-Augmented Generation (RAG) Added
Nodes A, B, B.1, B.2, B.3, C, D, D.1, D.2, D.3, E, E.1, E.2, E.3, E.4, E.5, E.6, E.7,
F, F.1, F.2, F.3, F.4, F.5, F.6, G, G.1, G.2, G.3, G.4, G.5, G.6 Declared. 

Forecast Title: \[Insert Forecast Title Here]
Forecaster: \[Insert Forecaster Name Here]

Initial Question Framing
Question: \[Insert your forecasting question here.]
Clarifications:
• \[Insert relevant details about dates, participants, key conditions, or assumptions.]
• \[Insert any known results, baselines, or thresholds.]
• \[Insert any poll data, prior trends, or framing context.]
Key Sources:
• \[Source 1]
• \[Source 2]
• \[Source 3]
• \[Add more as needed]

Refinement & Analysis
Key Developments:
• \[Summarize major events or dynamics relevant to the forecast question.]
• \[Note polling trends, market behavior, public sentiment, or institutional actions.]
• \[Include controversies, endorsements, or strategic shifts if relevant.]
Interpretation:
\[Explain how the developments influence your forecast. Discuss possible pathways,
leverage points, or conditional dependencies. Summarize why you're leaning a certain way.]

Note: If the forecast outcome is near a bucket threshold, 
consider hedging your probabilities across adjacent bins to avoid overconfidence.
Overweighting a single bucket—even if correct 
can result in a poor Brier score if the outcome lies near the edge.]

Inside-Outside View Structuring
Inside View: \[Insert short-term or domain-specific reasoning from known context.]
Outside View: \[Insert baseline rates, historic cases, or comparative reference classes.]

Data Anomaly & Source Integrity Log
Date Range Affected: \[Insert applicable date range]
Observed Anomaly: \[Describe any unusual or inconsistent data]
Identified Cause: \[Explain known or suspected reason for the anomaly]
Implication for Forecast: \[Describe the forecast impact if any]
Action Taken: \[Describe any adjustment or caveat added due to this anomaly]

// Structured Swarm Section — Applies only if forecast used multi-node reasoning
// Mode: Structured Swarm (5 Nodes, MSCFT.MS-CMT applied internally)

// Node Invocation Declaration: Nodes Used:
- A, B, B.1, B.2, B.3, C, D, D.1, D.2, E, F, F.1, F.2, F.3, F.4, F.5, F.6.
- G, G.1, G.2, G.3, G.4, G.5, G.6
// MSCFT Template v4.2 – Master Swarm Consensus Forecasting Template
// Cleaned formatting for node declarations and internal structure clarity

// Node A: Research Node — framing, question structure, source listing
A.1 – Forecast Question
A.2 – Resolution Source
A.3 – Forecast Window
A.4 – Source Protocol Indexing
A.4.a – Legal or Policy Framework Referenced
A.4.b – Organizational or System-Level Constraints
A.4.c – Governance Reference (if applicable)
// Example: Microsoft AI Agent Governance Whitepaper (2025), Sections 2.1–4.3

// Node B: Analytical Node — probability estimate, reasoning
B.1 – Known Drivers and Catalysts
B.2 – Limiting Factors
B.3 – Actor Incentives and Strategic Intent
B.4 – Historical Analogues or Relevant Models
B.5 – Risk Model Integration
B.5.a – Expected Value or Risk Exposure Range
B.5.b – AI Agent Risk Modeling
// Example: Role-bound CoPilot, Sentinel logging, pilot-phase agents only

// Node B.1: Multi-Step “Yes vs. No” Reflection Prompt (for binary questions only)
// (1) Rephrase the forecast as a binary statement
// (2) Argue Yes and No sides
// (3) Aggregate and assign forecast percentage
// (4) Re-evaluate for overconfidence

// Node B.2: BIN Model Substructure (Bias, Information, Noise)
Bias –
Information –
Noise –

// Node B.3: Uncertainty Quantification Method
// (1) Point estimate
// (2) 90% CI
// (3) Factors that widen/narrow range
// (4) Express noise/variance

// Node C: Synthesis Node — applies MSCFT.MS-CMT logic
C.1 – Scenario Buckets or Ranges
C.2 – Conditional Relationships Between Buckets
C.3 – AI Agent Taxonomy Alignment
C.3.a – Agent Lifecycle Tag: Pilot / Departmental / Enterprise-Wide
C.3.b – Governance Constraints and Deployment Stage
C.4 – Final Forecast Summary
C.5 – Rationale for Probability Distribution
C.6 – Forecast Caveats and Error Pathways

// Node D: Interpretation Node — Markov chain, entropy, or KL divergence
D.1 – Entropy or Volatility Classification
D.2 – Markov Memory or Decay Factors
D.3 – KL Divergence from Historical Baseline
D.4 – Edge Case Divergence and Rare Events
D.5 – Optional: Human Analyst Override

// Node D.1 Entropy Interpretation — H(p) = –∑ p log p
// Node D.2 Optional Symbolic Logic: Stack, Trie, Tree, Graph

// Node E: Time Series Modeling Node
E.1 – Anchor Point Identification
E.2 – Time Lag or Delay Window
E.3 – Forecast Window Resolution Points
E.4 – Time Series Feature Commentary (ARIMA, rolling average, etc.)
E.5 – ETS
E.6 – Fourier series
E.7 – Spectral entropy

// Node F: Retrieval-Augmented Generation (RAG) Node
F.1 – Objective of Retrieval
F.2 – Source Landscape and Corpus Overview
F.3 – Relevance Mapping to Forecast Scope
F.4 – Retrieval Scope Boundaries and Guardrails
F.4.a – Domain Constraints or Index Sharding
F.4.b – Time-Bound Access or Context Filters
F.4.c – Governance-Specific Retrieval Guardrails
F.5 – Impact on Forecast Validity
F.6 – Human-in-the-Loop Review and Injection Mitigation

// Node G: Meta-Curation and Data Integrity Node
G.1 – Source Provenance and Input Traceability
G.2 – Tool Use Disclosure and Agent Declaration
G.3 – Role Assignment and Input Segmentation
G.4 – Adversarial or Redundant Forecast Resolution
G.5 – Agent Execution Log and Governance Tracking
G.6 – Final Integrity Verification

// Optional Node G.7 – Governance and Compliance Declaration
G.7.a – Framework Compliance
G.7.b – Versioning and Role Alignment
G.7.c – Audit Log Availability


Refinement & Analysis
Key Developments:
• \[Summarize major events or dynamics relevant to the forecast question.]
• \[Note polling trends, market behavior, public sentiment, or institutional actions.]
• \[Include controversies, endorsements, or strategic shifts if relevant.]

Interpretation:
\[Explain how the developments influence your forecast.
Discuss possible pathways, leverage points, or conditional dependencies.
Summarize why you're leaning a certain way.]

Inside-Outside View Structuring:

Inside View: 
\[Insert short-term or domain-specific reasoning from known context.]
Outside View: 
\[Insert baseline rates, historic cases, or comparative reference classes.]

Data Anomaly & Source Integrity Log
Date Range Affected: \[Insert applicable date range]
Observed Anomaly: \[Describe any unusual or inconsistent data]
Identified Cause: \[Explain known or suspected reason for the anomaly]
Implication for Forecast: \[Describe the forecast impact if any]
Action Taken: \[Describe any adjustment or caveat added due to this anomaly]

Probability Allocation
Assign a percentage probability to each of the GJO, RANGE or Metaculus-aligned buckets.
Ensure they total to 100%. Do not use ranges that are ambiguous or overlapping.

If the question is binary (Yes/No), use:
• Yes: \[   ]%
• No:  \[   ]%

For multi-range buckets:
• 2 or fewer:          \[   ]%
• Between 3 and 5:     \[   ]%
• Between 6 and 8:     \[   ]%
• Between 9 and 12:    \[   ]%
• Between 13 and 16:   \[   ]%
• Between 17 and 21:   \[   ]%
• 22 or more:          \[   ]%
[Addition to Probability Allocation Section for Metaculus Slider Questions]

Note for Metaculus Slider Questions:  
Metaculus uses a continuous probability slider rather than discrete buckets.
For accurate modeling, the human forecaster must manually provide
the slider’s defined value ranges. This typically includes five thresholds:  

• Less than   [X]%  
• Lower 25%   (e.g., –Y%)  
• Median      (e.g., –Z%)  
• Upper 75%   (e.g., +A%)  
• Greater than [B]%  

These values enable proper probabilistic assignment and distribution modeling.
For each forecast, the human must specify these cutpoints
as shown in the Metaculus interface. Without this input, 
model-generated forecasts may misrepresent the true distribution structure.

// BIN Model Substructure (Bias, Information, Noise)
Bias –
\[Describe systemic, institutional, cognitive, or structural biases.]

Information –
\[Assess quality, timeliness, resolution, credibility, and gaps in data.]

Noise –
\[Identify irrelevant, misleading, or low-signal data distortions.]

//Final Forecast Summary
Forecast: \[Summarize the most likely outcome and your top bucket(s)]

// Rationale for Probability Distribution
Rationale: \[Explain the reasoning behind your distribution. What supports each weighting?]

// Forecast Caveats and Error Pathways
Why Might You Be Wrong?

1. \[Insert potential forecast error #1]
2. \[Insert potential forecast error #2]
3. \[Insert potential forecast error #3]
